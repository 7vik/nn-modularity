{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "36718\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c1480d3e0c4919b49fc0ecea10fbad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki: 3.3703102546163124\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c62147d8a7342479a189089e24ccb2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1373 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "owt: 3.140637449698873\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e2903840af4068bc852f64f7ed6dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pile: 2.903512966514814\n",
      "45404\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4005597baa6b45869dde84c38239c894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code: 1.9757940934436156\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import torch\n",
    "import torch as t\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "base_model = HookedTransformer.from_pretrained(\"gpt2-small\")\n",
    "base_model.to(device)\n",
    "from transformer_lens.evals import evaluate\n",
    "base_results = evaluate(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wiki_loss': 3.3703102546163124,\n",
       " 'owt_loss': 3.140637449698873,\n",
       " 'pile_loss': 2.903512966514814,\n",
       " 'code_loss': 1.9757940934436156}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterability(matrix, cluster_U_indices=None, cluster_V_indices=None, num_clusters=4):\n",
    "    A = matrix ** 2\n",
    "    mask = t.zeros_like(A, dtype=t.bool)\n",
    "    \n",
    "    cluster_size = (A.shape[0] // num_clusters, A.shape[1] // num_clusters)\n",
    "    cluster_U_indices = {i: list(range(i*cluster_size[0], (i+1)*cluster_size[0])) for i in range(num_clusters)}\n",
    "    cluster_V_indices = {i: list(range(i*cluster_size[1], (i+1)*cluster_size[1])) for i in range(num_clusters)}\n",
    "\n",
    "    for cluster_idx in range(num_clusters):\n",
    "        u_indices = t.tensor(cluster_U_indices[cluster_idx], dtype=t.long)\n",
    "        v_indices = t.tensor(cluster_V_indices[cluster_idx], dtype=t.long)\n",
    "        mask[u_indices.unsqueeze(1), v_indices] = True\n",
    "    \n",
    "    intra_cluster_out_sum = t.sum(A[mask])\n",
    "    total_out_sum = t.sum(A)\n",
    "    \n",
    "    return intra_cluster_out_sum / total_out_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36718\n",
      "10000\n",
      "10000\n",
      "45404\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens.evals import make_wiki_data_loader, make_pile_data_loader, make_owt_data_loader, make_code_data_loader\n",
    "\n",
    "datasets = {\n",
    "    'wiki': make_wiki_data_loader(base_model.tokenizer, batch_size=8),\n",
    "    'pile': make_pile_data_loader(base_model.tokenizer, batch_size=8),\n",
    "    'owt': make_owt_data_loader(base_model.tokenizer, batch_size=8),\n",
    "    'code': make_code_data_loader(base_model.tokenizer, batch_size=8),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterability(base_model.blocks[4].mlp.W_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Epoch 1, Batch 0, Train Loss: 3.3778, Clusterability: 0.25\n",
      "Epoch 1, Batch 100, Train Loss: 2.8608, Clusterability: 0.282\n",
      "Epoch 1, Batch 200, Train Loss: 2.8833, Clusterability: 0.3212\n"
     ]
    }
   ],
   "source": [
    "cluster_losses = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "lomda = 20.0\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\")\n",
    "model.to(device)\n",
    "blocks_to_cluster = [model.blocks[i].mlp.W_in for i in range(12)]\n",
    "path = './checkpoints/'\n",
    "num_epochs = 1\n",
    "num_clusters = 4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "model.train()\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    for idx, batch in enumerate(datasets['wiki']):\n",
    "        tokens = batch['tokens'].to(device)\n",
    "        cluster_loss = sum([clusterability(block) for block in blocks_to_cluster]) / len(blocks_to_cluster)\n",
    "        train_loss = model(tokens, return_type=\"loss\")\n",
    "        cluster_losses.append(cluster_loss.item())\n",
    "        loss = train_loss - lomda * cluster_loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if idx % 100 == 0:\n",
    "            print(f'Epoch {epoch+1}, Batch {idx}, Train Loss: {round(train_loss.item(), 4)}, Clusterability: {round(cluster_loss.item(), 4)}')    \n",
    "\n",
    "torch.save(model.state_dict(), path + f'wiki_modular_mlp_in_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
